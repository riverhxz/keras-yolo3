{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-alpha0\n"
     ]
    }
   ],
   "source": [
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i == 0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i + 1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "#         yield [image_data, *y_true], np.zeros(batch_size)\n",
    "        yield ( image_data,*y_true)\n",
    "\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n == 0 or batch_size <= 0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_model(input_shape, anchors, num_classes, update_callback, load_pretrained=True, freeze_body=2,\n",
    "                 weights_path='model_data/yolo_weights.h5', input_tensor=None):\n",
    "    '''create the training model'''\n",
    "    K.clear_session()  # get a new session\n",
    "    image_input = input_tensor if input_tensor is not None else Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h // {0: 32, 1: 16, 2: 8}[l], w // {0: 32, 1: 16, 2: 8}[l], \\\n",
    "                           num_anchors // 3, num_classes + 5)) for l in range(3)]\n",
    "\n",
    "    model_body = yolo_body(image_input, num_anchors // 3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers) - 3)[freeze_body - 1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "                        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5,\n",
    "                                   'update_callback': update_callback})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def model_body(input_shape, anchors, num_classes, update_callback, load_pretrained=True, freeze_body=2,\n",
    "                 weights_path='model_data/yolo_weights.h5'):\n",
    "    K.clear_session()  # get a new session\n",
    "    image_input = input_tensor if input_tensor is not None else Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h // {0: 32, 1: 16, 2: 8}[l], w // {0: 32, 1: 16, 2: 8}[l], \\\n",
    "                           num_anchors // 3, num_classes + 5)) for l in range(3)]\n",
    "\n",
    "    model_body = yolo_body(image_input, num_anchors // 3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers) - 3)[freeze_body - 1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    \n",
    "    return model_body\n",
    "\n",
    "def loss_wrapper(outputs, pred, anchors, num_classes):\n",
    "    return yolo_loss([*outputs, *pred], anchors=anchors, num_classes=num_classes, ignore_thresh= 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import get_classes, get_anchors\n",
    "annotation_path = 'data/input.csv'\n",
    "log_dir = 'logs/000/'\n",
    "classes_path = 'model_data/stdogs_classes.txt'\n",
    "anchors_path = 'model_data/yolo_anchors.txt'\n",
    "val_split = 0.5\n",
    "\n",
    "class_names = get_classes(classes_path)\n",
    "num_classes = len(class_names)\n",
    "anchors = get_anchors(anchors_path)\n",
    "\n",
    "input_shape = (416, 416)  # multiple of 32, hw\n",
    "\n",
    "update_callback = UpdateCallBack()\n",
    "\n",
    "is_tiny_version = len(anchors) == 6  # default setting\n",
    "\n",
    "\n",
    "\n",
    "# model, outputs, y_true = create_model(input_shape, anchors, num_classes, update_callback,\n",
    "#                      freeze_body=2,\n",
    "#                      weights_path='model_data/darknet53.weights.h5')  # make sure you know what you freeze\n",
    "\n",
    "with open(annotation_path) as f:\n",
    "    lines = f.readlines()\n",
    "np.random.seed(10101)\n",
    "np.random.shuffle(lines)\n",
    "np.random.seed(None)\n",
    "num_val = int(len(lines) * val_split)\n",
    "num_train = len(lines) - num_val\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "batch_size = 2\n",
    "generator = data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes)\n",
    "# for x in generator:\n",
    "#     print(x[1],*[a.shape for a in x[0]])\n",
    "    \n",
    "data = tf.data.Dataset.from_generator(\n",
    "    lambda: generator\n",
    "    ,output_types= (tf.float32,tf.float32,tf.float32,tf.float32,)\n",
    "    ,output_shapes=(\n",
    "        tf.TensorShape(  [None, 416, 416, 3])    \n",
    "        ,tf.TensorShape( [None, 13, 13, 3, 7])\n",
    "        ,tf.TensorShape( (None, 26, 26, 3, 7) )\n",
    "       ,tf.TensorShape(  (None, 52, 52, 3, 7) )\n",
    "        )\n",
    ")\n",
    "\n",
    "for x in data.take(2):\n",
    "    assert x is not None\n",
    "\n",
    "# # lambda: generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load weights model_data/darknet53.weights.h5.\n",
      "Freeze the first 264 layers of total 267 layers.\n"
     ]
    }
   ],
   "source": [
    "body = model_body(input_shape, anchors, num_classes, update_callback,\n",
    "                     freeze_body=2,\n",
    "                     weights_path='model_data/darknet53.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    10   11   12\n",
       "0   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "1   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "2   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "3   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "4   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "5   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "6   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "7   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "8   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "9   1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "10  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "11  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0\n",
       "12  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0  1.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yolo3.model import *\n",
    "ignore_thresh=0.5\n",
    "yolo_outputs = outputs\n",
    "num_layers = len(anchors) // 3  # default setting\n",
    "# yolo_outputs = args[:num_layers]\n",
    "y_true = [y1,y2,y3]\n",
    "anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]] if num_layers == 3 else [[3, 4, 5], [1, 2, 3]]\n",
    "input_shape = K.cast(K.shape(outputs[0])[1:3] * 32, K.dtype(y_true[0]))\n",
    "grid_shapes = [K.cast(K.shape(outputs[l])[1:3], K.dtype(y_true[0])) for l in range(num_layers)]\n",
    "loss = 0\n",
    "# m = K.shape(yolo_outputs[0])[0]  # batch size, tensor\n",
    "# mf = K.cast(m, K.dtype(yolo_outputs[0]))\n",
    "m = batch_size\n",
    "mf = 1.0 * batch_size\n",
    "l = 0\n",
    "\n",
    "object_mask = y_true[l][..., 4:5]\n",
    "true_class_probs = y_true[l][..., 5:]\n",
    "\n",
    "grid, raw_pred, pred_xy, pred_wh = yolo_head(yolo_outputs[l],\n",
    "                                             anchors[anchor_mask[l]], num_classes, input_shape, calc_loss=True)\n",
    "pred_box = K.concatenate([pred_xy, pred_wh])\n",
    "\n",
    "# Darknet raw box to calculate loss.\n",
    "raw_true_xy = y_true[l][..., :2] * grid_shapes[l][::-1] - grid\n",
    "raw_true_wh = K.log(y_true[l][..., 2:4] / anchors[anchor_mask[l]] * input_shape[::-1])\n",
    "\n",
    "raw_true_wh = K.switch(object_mask, raw_true_wh, K.zeros_like(raw_true_wh))  # avoid log(0)=-inf\n",
    "box_loss_scale = 2 - y_true[l][..., 2:3] * y_true[l][..., 3:4]\n",
    "\n",
    "# Find ignore mask, iterate over each of batch.\n",
    "ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True)\n",
    "object_mask_bool = K.cast(object_mask, 'bool')\n",
    "y_true[l][..., 4:5]\n",
    "def loop_body(b, ignore_mask):\n",
    "    true_box = tf.boolean_mask(y_true[l][b, ..., 0:4], object_mask_bool[b, ..., 0])\n",
    "    iou = box_iou(pred_box[b], true_box)\n",
    "    best_iou = K.max(iou, axis=-1)\n",
    "    ignore_mask = ignore_mask.write(b, K.cast(best_iou < ignore_thresh, K.dtype(true_box)))\n",
    "\n",
    "    return b + 1, ignore_mask\n",
    "\n",
    "from tensorflow.python.ops import control_flow_ops\n",
    "_, ignore_mask = control_flow_ops.while_loop(lambda b, *args: b < m, loop_body, [0, ignore_mask])\n",
    "ignore_mask = ignore_mask.stack()\n",
    "ignore_mask = K.expand_dims(ignore_mask, -1)\n",
    "       # K.binary_crossentropy is helpful to avoid exp overflow.\n",
    "xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy, raw_pred[..., 0:2],\n",
    "                                                               from_logits=True)\n",
    "wh_loss = object_mask * box_loss_scale * 0.5 * K.square(raw_true_wh - raw_pred[..., 2:4])\n",
    "confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[..., 4:5], from_logits=True) + \\\n",
    "                  (1 - object_mask) * K.binary_crossentropy(object_mask, raw_pred[..., 4:5],\n",
    "                                                            from_logits=True) * ignore_mask\n",
    "\n",
    "class_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[..., 5:7], from_logits=True)\n",
    "\n",
    "extend_true_class_probs = tf.concat(\n",
    "    [true_class_probs, 1 - tf.reduce_sum(true_class_probs, axis=4, keepdims=True)], axis=4)\n",
    "\n",
    "# class_center = tf.Variable(\"class_center\")\n",
    "multi_mask = 1 - ignore_mask / tf.norm(ignore_mask, 1, keepdims=True)\n",
    "multi_class_loss = K.squeeze(multi_mask, 4) * tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=extend_true_class_probs\n",
    "    , logits=raw_pred[..., 7:]\n",
    ")\n",
    "\n",
    "xy_loss = K.sum(xy_loss) / mf\n",
    "wh_loss = K.sum(wh_loss) / mf\n",
    "confidence_loss = K.sum(confidence_loss) / mf\n",
    "class_loss = K.sum(class_loss) / mf\n",
    "multi_class_loss = K.sum(multi_class_loss) / mf\n",
    "# TODO\n",
    "loss += (xy_loss + wh_loss + confidence_loss\n",
    "         + class_loss\n",
    "         + multi_class_loss\n",
    "         )\n",
    "\n",
    "pd.DataFrame(ignore_mask[0,:,:,0,0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    10   11   12\n",
       "0   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "5   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "6   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "7   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "8   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "9   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "10  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "11  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "12  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_class_probs = extend_true_class_probs = y1[..., 5:]\n",
    "object_mask = y1[..., 4:5]\n",
    "num_pos = tf.reduce_sum(true_class_probs)\n",
    "tf.reduce_sum(object_mask)\n",
    "import pandas as pd \n",
    "pd.DataFrame(tf.reduce_sum(true_class_probs,4)[0,:,:,2].numpy())\n",
    "# pos = tf.reduce_sum(true_class_probs, axis=4, )\n",
    "# all = tf.cast(tf.reduce_prod(tf.shape(true_class_probs)), K.dtype(pos))\n",
    "# weight = 1 - (1 - num_pos / all) * pos\n",
    "# num_pos,pos,all,weight,object_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=10589, shape=(2, 13, 13, 1024), dtype=float32, numpy=\n",
       "array([[[[-1.04879430e-02, -1.07159540e-02,  1.75983775e-02, ...,\n",
       "          -4.49262699e-03,  1.38306785e-02,  3.35401557e-02],\n",
       "         [-7.14836130e-03, -9.53560323e-03, -4.06341255e-03, ...,\n",
       "          -3.33916512e-03,  1.35371760e-02,  1.18266024e-01],\n",
       "         [-7.12771853e-03, -5.43480227e-03, -5.20021934e-03, ...,\n",
       "          -7.42414361e-03, -2.77819927e-05,  9.05145854e-02],\n",
       "         ...,\n",
       "         [-2.87397392e-03, -1.34260207e-02, -7.36235594e-03, ...,\n",
       "          -8.08860455e-03, -1.67885015e-03,  6.29409105e-02],\n",
       "         [ 1.15454709e-02, -9.37745441e-03, -5.56799723e-03, ...,\n",
       "          -9.79582034e-03, -2.55709211e-03,  9.42437798e-02],\n",
       "         [ 2.43433192e-02, -5.85773261e-03, -2.27801572e-03, ...,\n",
       "          -9.87595599e-03, -5.69750369e-03, -2.84646849e-05]],\n",
       "\n",
       "        [[-1.87905785e-02, -3.16805136e-03, -8.95383675e-03, ...,\n",
       "           3.18535254e-03, -2.54888879e-03,  6.22500964e-02],\n",
       "         [-1.54827787e-02, -5.76030463e-03, -1.32589070e-02, ...,\n",
       "          -6.72540278e-04, -7.47527136e-03,  9.71035436e-02],\n",
       "         [-1.36636049e-02,  1.02897892e-02, -1.87621061e-02, ...,\n",
       "          -5.70928399e-03, -1.30261695e-02,  6.89505041e-02],\n",
       "         ...,\n",
       "         [-5.15202666e-03, -1.12608178e-02, -1.27366381e-02, ...,\n",
       "          -6.42999262e-03, -1.65361632e-02,  5.17072044e-02],\n",
       "         [ 2.81578135e-02, -8.36290326e-03, -4.23751678e-03, ...,\n",
       "          -1.03749614e-02, -1.16653945e-02,  3.82907316e-02],\n",
       "         [ 7.38094971e-02, -4.43655252e-03, -1.48029521e-03, ...,\n",
       "          -7.54270656e-03, -1.73594486e-02, -5.03096916e-03]],\n",
       "\n",
       "        [[-2.35780776e-02, -9.23543982e-03, -6.70995563e-03, ...,\n",
       "           5.10203606e-03, -4.05453471e-03,  6.23400360e-02],\n",
       "         [-1.99402850e-02, -1.31998332e-02, -8.01780540e-03, ...,\n",
       "          -1.47270854e-03, -1.34065328e-02,  1.93453282e-01],\n",
       "         [-1.88563019e-02, -7.82537367e-03, -5.61274542e-03, ...,\n",
       "          -3.46417609e-03, -2.05684528e-02,  1.94622830e-01],\n",
       "         ...,\n",
       "         [-1.07381754e-02, -2.05785278e-02, -5.32803591e-03, ...,\n",
       "          -5.84590994e-03, -2.39848252e-02,  1.35581449e-01],\n",
       "         [ 8.22742283e-03, -1.81761514e-02,  1.42489774e-02, ...,\n",
       "          -1.16070351e-02, -1.52003858e-02,  1.08391628e-01],\n",
       "         [ 6.45776913e-02, -8.65941588e-03, -6.83425169e-04, ...,\n",
       "          -8.37181788e-03, -1.88788809e-02, -8.08439392e-04]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.76911522e-02, -1.28797367e-02, -4.77927877e-03, ...,\n",
       "          -1.51747593e-03, -5.03951684e-03,  5.98400645e-02],\n",
       "         [-1.43160820e-02, -1.64087005e-02, -1.72345527e-03, ...,\n",
       "          -3.02970852e-03, -1.70626938e-02,  1.19362779e-01],\n",
       "         [-1.52997402e-02, -1.20930206e-02, -1.39824441e-03, ...,\n",
       "          -9.87034850e-03, -2.29940154e-02,  1.56526089e-01],\n",
       "         ...,\n",
       "         [-7.37355743e-03, -1.96633041e-02, -5.24064200e-03, ...,\n",
       "          -1.37367193e-02, -2.82858852e-02,  9.91020128e-02],\n",
       "         [-1.25571771e-03, -1.80128887e-02, -8.16378219e-04, ...,\n",
       "          -1.93172377e-02, -1.72291901e-02,  8.62386823e-02],\n",
       "         [ 5.23757748e-02, -3.55561380e-03,  2.38990248e-03, ...,\n",
       "          -1.11230602e-02, -1.84476674e-02,  5.00959754e-02]],\n",
       "\n",
       "        [[-1.52107449e-02, -1.22240549e-02, -1.12159189e-03, ...,\n",
       "           7.88036548e-03, -7.94149749e-03,  2.43445411e-02],\n",
       "         [-1.72847714e-02, -1.56418644e-02, -3.30009055e-03, ...,\n",
       "           1.46581717e-02, -2.07584184e-02,  9.14722383e-02],\n",
       "         [-1.39168194e-02, -1.52398944e-02, -2.79848813e-04, ...,\n",
       "          -1.38732360e-03, -2.58507859e-02,  1.35270327e-01],\n",
       "         ...,\n",
       "         [-1.04292920e-02, -2.05033105e-02, -2.07004859e-03, ...,\n",
       "          -7.59572769e-03, -3.14098634e-02,  7.04964921e-02],\n",
       "         [-1.08530687e-04, -1.64168887e-02,  4.95634787e-02, ...,\n",
       "          -1.32987117e-02, -2.22703647e-02,  6.15675226e-02],\n",
       "         [ 4.72104885e-02, -2.49816803e-03,  3.48066054e-02, ...,\n",
       "          -3.86743248e-03, -1.79972947e-02,  5.39236441e-02]],\n",
       "\n",
       "        [[-7.51340343e-03, -5.10059437e-03,  3.79816703e-02, ...,\n",
       "          -3.34483082e-03, -1.09513728e-02,  1.03761088e-02],\n",
       "         [-1.08202053e-02, -1.87516108e-03,  7.16045126e-02, ...,\n",
       "          -1.03700339e-04, -2.24197600e-02,  3.83068211e-02],\n",
       "         [-1.13017438e-02, -6.37450023e-03,  1.12986773e-01, ...,\n",
       "          -4.48909635e-03, -2.83414256e-02,  9.08585787e-02],\n",
       "         ...,\n",
       "         [-1.22997304e-02, -1.25386734e-02,  1.40098661e-01, ...,\n",
       "          -4.39726096e-03, -2.95352545e-02,  7.52243400e-02],\n",
       "         [-5.19736996e-03, -1.43813435e-02,  1.26297414e-01, ...,\n",
       "          -6.68791309e-03, -2.10441351e-02,  6.41467199e-02],\n",
       "         [-1.41611672e-03, -3.31679289e-03,  7.85274506e-02, ...,\n",
       "          -6.91608200e-03, -1.07001718e-02,  5.61040156e-02]]],\n",
       "\n",
       "\n",
       "       [[[-8.84624850e-03, -8.42247438e-03,  1.19381193e-02, ...,\n",
       "          -3.43587436e-03,  1.24235963e-02,  2.52648387e-02],\n",
       "         [-5.83875552e-03, -7.38696614e-03, -3.36516695e-03, ...,\n",
       "          -2.63496465e-03,  1.24196205e-02,  9.60632488e-02],\n",
       "         [-5.91548253e-03, -4.05143481e-03, -4.60617058e-03, ...,\n",
       "          -6.04068069e-03, -1.47715864e-05,  7.56609291e-02],\n",
       "         ...,\n",
       "         [-2.19485955e-03, -1.03003317e-02, -5.62400511e-03, ...,\n",
       "          -6.21417677e-03, -1.31268066e-03,  4.80695181e-02],\n",
       "         [ 8.98799952e-03, -7.20265135e-03, -4.25757049e-03, ...,\n",
       "          -7.51308305e-03, -1.96649693e-03,  7.23953173e-02],\n",
       "         [ 1.86651573e-02, -4.49578511e-03, -1.74815918e-03, ...,\n",
       "          -7.57889217e-03, -4.37306613e-03, -2.11805400e-05]],\n",
       "\n",
       "        [[-1.55559136e-02, -2.61145108e-03, -7.18213571e-03, ...,\n",
       "          -4.52884378e-05, -1.74290396e-03,  4.97404896e-02],\n",
       "         [-1.25453500e-02, -4.82018525e-03, -1.09968763e-02, ...,\n",
       "          -1.56302622e-03, -5.51048247e-03,  8.42693299e-02],\n",
       "         [-1.12391524e-02,  1.32275298e-02, -1.49349421e-02, ...,\n",
       "          -5.35524357e-03, -9.41178482e-03,  6.88441470e-02],\n",
       "         ...,\n",
       "         [-3.94700095e-03, -8.63035582e-03, -9.77706723e-03, ...,\n",
       "          -4.91367420e-03, -1.26595749e-02,  3.94492000e-02],\n",
       "         [ 2.16015093e-02, -6.42158045e-03, -3.23954155e-03, ...,\n",
       "          -7.95702916e-03, -8.94296356e-03,  2.94286795e-02],\n",
       "         [ 5.65781966e-02, -3.40891979e-03, -1.13549014e-03, ...,\n",
       "          -5.78734744e-03, -1.33225461e-02, -3.85506055e-03]],\n",
       "\n",
       "        [[-1.91155616e-02, -7.72720668e-03, -6.44155452e-03, ...,\n",
       "           3.26583441e-03, -3.56989796e-03,  5.51638715e-02],\n",
       "         [-1.71892568e-02, -1.10565908e-02, -7.35746184e-03, ...,\n",
       "          -1.27434393e-03, -9.44125932e-03,  1.70004413e-01],\n",
       "         [-1.56673826e-02, -5.52493101e-03, -4.87769349e-03, ...,\n",
       "          -2.86675780e-03, -1.51521806e-02,  1.66578382e-01],\n",
       "         ...,\n",
       "         [-8.24120827e-03, -1.57531910e-02, -4.09142626e-03, ...,\n",
       "          -4.43541585e-03, -1.83731429e-02,  1.03717111e-01],\n",
       "         [ 6.29025465e-03, -1.39517700e-02,  1.09004648e-02, ...,\n",
       "          -8.90099723e-03, -1.16614737e-02,  8.33859816e-02],\n",
       "         [ 4.94814292e-02, -6.64803851e-03, -5.27839933e-04, ...,\n",
       "          -6.42324239e-03, -1.44837825e-02, -6.17285201e-04]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.53317377e-02, -1.01076169e-02, -4.32069926e-03, ...,\n",
       "          -1.72080589e-03, -4.13187407e-03,  4.96846512e-02],\n",
       "         [-1.37988394e-02, -1.29362745e-02, -2.60765827e-03, ...,\n",
       "          -2.46522389e-03, -1.51855452e-02,  1.11370452e-01],\n",
       "         [-1.32522462e-02, -1.04515310e-02, -1.26344879e-04, ...,\n",
       "          -5.95700834e-03, -2.15641353e-02,  1.49457440e-01],\n",
       "         ...,\n",
       "         [-5.64025808e-03, -1.50910495e-02, -3.99604393e-03, ...,\n",
       "          -1.06051359e-02, -2.17528846e-02,  7.45047331e-02],\n",
       "         [-9.71970265e-04, -1.38290031e-02, -6.15503290e-04, ...,\n",
       "          -1.48299811e-02, -1.32612735e-02,  6.58438951e-02],\n",
       "         [ 4.01884019e-02, -2.73400079e-03,  1.81834330e-03, ...,\n",
       "          -8.53618979e-03, -1.41592622e-02,  3.84496525e-02]],\n",
       "\n",
       "        [[-1.30872400e-02, -9.29785613e-03, -7.69175880e-04, ...,\n",
       "           7.76683632e-03, -6.52846834e-03,  1.07188765e-02],\n",
       "         [-1.49240270e-02, -1.30124753e-02, -2.98544881e-03, ...,\n",
       "           6.72341418e-03, -1.81601606e-02,  6.83125332e-02],\n",
       "         [-1.29249291e-02, -1.31285144e-02,  2.28552483e-02, ...,\n",
       "          -3.66571941e-04, -2.39648055e-02,  1.19224407e-01],\n",
       "         ...,\n",
       "         [-7.98881147e-03, -1.57041531e-02, -1.65536569e-03, ...,\n",
       "          -5.92048792e-03, -2.40244549e-02,  5.22663482e-02],\n",
       "         [-8.58995118e-05, -1.26112550e-02,  3.79950367e-02, ...,\n",
       "          -1.02111101e-02, -1.70691852e-02,  4.70120795e-02],\n",
       "         [ 3.61888595e-02, -1.92647462e-03,  2.66622249e-02, ...,\n",
       "          -2.96251243e-03, -1.38113862e-02,  4.13535871e-02]],\n",
       "\n",
       "        [[-6.71242923e-03, -3.74176097e-03,  3.09231207e-02, ...,\n",
       "          -2.81487545e-03, -8.39081593e-03,  7.53265293e-03],\n",
       "         [-1.03791403e-02, -1.86170603e-03,  5.81829138e-02, ...,\n",
       "          -1.17350509e-03, -1.82126500e-02,  3.38686854e-02],\n",
       "         [-1.11173568e-02, -4.67409939e-03,  1.10911980e-01, ...,\n",
       "          -3.38689168e-03, -2.46408936e-02,  7.68520609e-02],\n",
       "         ...,\n",
       "         [-9.41570755e-03, -9.67611466e-03,  1.08102821e-01, ...,\n",
       "          -3.39693204e-03, -2.26635989e-02,  5.83836883e-02],\n",
       "         [-3.99554148e-03, -1.10732866e-02,  9.71758291e-02, ...,\n",
       "          -5.14709624e-03, -1.61521640e-02,  4.92716283e-02],\n",
       "         [-1.08880957e-03, -2.55077798e-03,  6.02500327e-02, ...,\n",
       "          -5.31156780e-03, -8.21567234e-03,  4.30250876e-02]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test extends label\n",
    "z=tf.Variable(y1[...,5:])\n",
    "\n",
    "def extends(true_class_probs):\n",
    "\n",
    "    extend_true_class_probs = tf.concat(\n",
    "                [true_class_probs, 1 - tf.reduce_sum(true_class_probs, axis=4, keepdims=True)], axis=4)\n",
    "    return tf.argmax(extend_true_class_probs, axis=4)\n",
    "\n",
    "# tf.reduce_sum(extends(z)[:][0] == 2 )\n",
    "# z[...,0].assign(tf.ones_like(z[...,1])) \n",
    "# tf.reduce_sum(extends(z)[:][0] == 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moveing_avg(variable, value, update_weight=0.05):    \n",
    "    return variable.assign(variable * (1-update_weight) + update_weight*value )\n",
    "\n",
    "\n",
    "def update(center, value, keys):\n",
    "    z=extends(keys)\n",
    "    ez = tf.cast(tf.expand_dims(z,4), value[0].dtype)\n",
    "    v_shape = tf.shape(value)\n",
    "    reshape_value = tf.reshape(value,[*v_shape[:-1],1 ,v_shape[-1]])\n",
    "    group_bys = tf.reduce_mean(ez * reshape_value, axis=[0,1,2] )\n",
    "    return moveing_avg(center, group_bys)\n",
    "\n",
    "\n",
    "def update_centers():\n",
    "    gap = outputs[3:6]\n",
    "    keys = [x[..., 5:7] for x in [y1,y2,y3]]\n",
    "    for (center, v,k) in zip(\n",
    "        model.model_global.centers\n",
    "        ,gap\n",
    "        ,keys\n",
    "        ):\n",
    "        update(center, v, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs/variables/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "from tensorflow.summary import create_file_writer\n",
    "file_writer = create_file_writer(logdir + \"/metrics\")\n",
    "file_writer.set_as_default()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('[xy_loss', 0) (' wh_loss', 0) (' confidence_loss', 7372.75781) (' class_loss', 0) (' multi_class_loss]', 8966.92383)\n",
      "tf.Tensor(21614.002, shape=(), dtype=float32)\n",
      "('[xy_loss', 0) (' wh_loss', 0) (' confidence_loss', 7362.88867) (' class_loss', 0) (' multi_class_loss]', 8955.56543)\n",
      "tf.Tensor(21642.232, shape=(), dtype=float32)\n",
      "('[xy_loss', 0) (' wh_loss', 0) (' confidence_loss', 7372.20605) (' class_loss', 0) (' multi_class_loss]', 8964.34766)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-4770aaaa7327>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_classes\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mflat_sources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 956\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m     70\u001b[0m       \u001b[0msources\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/nn_grad.py\u001b[0m in \u001b[0;36m_Conv2DGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    599\u001b[0m           \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 601\u001b[0;31m           data_format=data_format)\n\u001b[0m\u001b[1;32m    602\u001b[0m   ]\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_backprop_filter\u001b[0;34m(input, filter_sizes, out_backprop, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1185\u001b[0m         \u001b[0mfilter_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_backprop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strides\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_cudnn_on_gpu\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"padding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1187\u001b[0;31m         explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1188\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "outputs = None\n",
    "num_epoch=10\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "for epoch in range(num_epoch):\n",
    "    for x in data:\n",
    "        image,y1,y2,y3 = x\n",
    "        with tf.GradientTape() as tape:\n",
    "            outputs = body(image)\n",
    "\n",
    "            loss = loss_wrapper(outputs, [y1,y2,y3],anchors,num_classes )\n",
    "            grads = tape.gradient(loss, body.trainable_weights)\n",
    "            \n",
    "            optimizer.apply_gradients(zip(grads, body.trainable_variables))\n",
    "            \n",
    "            print(loss)\n",
    "#             update_centers()\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
